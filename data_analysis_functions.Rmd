---
title: "Functions for Data Analysis"
subtitle: "Nowcasting Latin America"
author: "Mariana Arrieta Yanez"
date: "6/2021"
output: html_document
---

```{r, message=FALSE}
library(tidyverse)
library(data.table)
library(lubridate)
library(gtrendsR)
library(janitor)
library(tools)
library(bsts)

```

### Data Cleaning

```{r}
processing_gt_monthly <- function(data_frame, category = categories){
  ###This function takes the raw data from Google trends and returns a clean dataframe
  ### where each variable index is averaged over each month
  
  #Merge without increasing dimensionality
  df_temp <- merge(data_frame, unique(categories[c("name", "category")]), by="category")
  df_temp <- df_temp %>%
    dplyr::select(-c(X, time, gprop, geo, category)) %>% #remove irrelevant rows
    relocate(date, name, hits) %>%
    mutate(date = ymd(date))
  #Round the date so it corresponds to survey times
  df_temp$year_month <- round_date(ymd(df_temp$date), "month")
  
  df_temp <- df_temp %>%
  relocate(date, year_month) %>% #organize cols
    distinct() %>% #remove duplicates 
    mutate(hits = as.numeric(hits)) %>%
    group_by(year_month, name) %>%
    #For some reason there were categories that had different hits values in the same weeks. A notable example was the Programming category
    #To deal with this, I take the average of these two hits values by grouping by date and category
    mutate(hits_n = round(mean(hits))) %>%
    ungroup() %>%
    dplyr::select(-c(hits, date))
    df_temp <- df_temp %>%
    rename(hits = hits_n) %>%
    distinct() %>%
    #NAs at this point represent categories that have had some interest in a week, but no interest at all in others. 
    #For this reason, I replace NAs with 0. 
    mutate_if(is.numeric , replace_na, replace = 0) %>% 
    pivot_wider(names_from = name, values_from = hits)
    
    #remove last observation
    df_temp <- df_temp %>% filter(row_number() <= n()-1)
    
  return(df_temp)
}



```


```{r}
#Function to Process consumer confidence data from csv file
process_cc <- function(country){
  df <- read.csv(paste(country, "cc.csv", sep = "/"))
  df$newdate <- strptime(as.character(df$Date), "%d/%m/%Y")
  df$newdate <- format(df$newdate, "%m/%Y")
  df$cc <- gsub("\\,", ".", df$cc)

  df <- df %>%
    dplyr::select(cc, newdate) %>%
    relocate(newdate) %>%
    rename(date= newdate) %>%
    mutate(cc = as.numeric(cc)) %>%
    mutate(date = my(date))
  
  return(df)
}
```


```{r}
#Function to merge consumer confidence and google trends data 
merge_and_label <- function(df_gt,df_cc){
  df_temp <- merge(df_gt, df_cc, by.x = "year_month", by.y = "date")

  df_temp <- df_temp %>%
    relocate(cc) %>%
    rename(date = year_month)
  
  #Remove year month variable
   df_temp <- df_temp[,!(names(df_temp) %in% c("year_month"))]

  
  return(df_temp)
  
}
```


```{r}
split_train_test <- function(df, initial_year){
  # list to store all data.frames
  out <- list()
  
  #Put together training set and clean it
  
    if(initial_year == 2017){
    train <-  df[1:33,]
  } else{
    train <-  df[1:27,]
  }
  
  train <- train %>% remove_rownames %>% column_to_rownames(var="date")
  out$train <- train
  
  #Put together test set and clean it
    if(initial_year == 2017){
    test_oct <-  df[34,]
    test_nov <-  df[35,]
    test_dec <-  df[36,]
 
  test_oct <- test_oct %>% remove_rownames %>% column_to_rownames(var="date")
  test_nov <- test_nov %>% remove_rownames %>% column_to_rownames(var="date")
  test_dec <- test_dec %>% remove_rownames %>% column_to_rownames(var="date")  
  
  out$test_oct <- test_oct
  out$test_nov <- test_nov
  out$test_dec <- test_dec
    
  } else{
    test_apr <-  df[28,]
    test_may <-  df[29,]
    test_jun <-  df[30,]
    
  test_apr <- test_apr %>% remove_rownames %>% column_to_rownames(var="date")
  test_may <- test_may %>% remove_rownames %>% column_to_rownames(var="date")
  test_jun <- test_jun %>% remove_rownames %>% column_to_rownames(var="date")  
  
  out$test_apr <- test_apr
  out$test_may <- test_may
  out$test_jun <- test_jun
  }
  
  
  
  return(out)
  }



```


```{r}
bsts_run <- function(y, model_spec, seasons, iterations, df, seed = 42){
  ss <- AddLocalLinearTrend(list(), y)
  ss <- AddSeasonal(ss, y, nseasons = seasons)
  model <- bsts(model_spec,
               state.specification = ss,
               data = df,
               niter = iterations, 
               seed = seed)
  
  return(model)
  
}
```

```{r}

prediction_df_and_plot <- function(model, full_df, train_df, pred_horizon = 3, test_1, test_2, test_3, reg, test_year= 2019, prior = FALSE){
  y <- as.numeric(train_df$cc)
  out <- list()
  ### Get a suggested number of burn-ins
  burn <- SuggestBurn(0.1, model)

  #Create datasets with updated information 
  update_1 <- rbind(train_df, test_1)
  update_2 <- rbind(update_1, test_2)
  if  (reg == TRUE & prior == FALSE){
  ### Predict
  p_1 <- predict(model, newdata = test_1 , burn = burn, quantiles = c(.025, .975))
  p_2 <- predict(model, newdata = test_2 , olddata = update_1, burn = burn,quantiles = c(.025, .975))
  p_3 <- predict(model, newdata = test_3 , olddata = update_2, burn = burn,quantiles = c(.025, .975))
  p_mean <- c(p_1$mean, p_2$mean, p_3$mean)
  title <- "Model with Regression"
  custom_fill <- "#FF5733"
  
  }else if (reg == TRUE & prior == TRUE){
  p_1 <- predict(model, newdata = test_1 , burn = burn, quantiles = c(.025, .975))
  p_2 <- predict(model, newdata = test_2 , olddata = update_1, burn = burn,quantiles = c(.025, .975))
  p_3 <- predict(model, newdata = test_3 ,  olddata = update_2, burn = burn,quantiles = c(.025, .975))
  
  p_mean <- c(p_1$mean, p_2$mean, p_3$mean)
   title <- "Model with Regression and Priors"
   custom_fill <- "#229954"
   
  } else {
  p <- predict.bsts(model, horizon = pred_horizon, burn = burn,quantiles = c(.025, .975)) 
  title <- "Model without Regression"
  custom_fill <-"#1B38D6"
  p_mean <- p$mean
  }

  
  ### Actual versus predicted
  d2 <- data.frame(
    # fitted values and predictions
      c(as.numeric(-colMeans(model$one.step.prediction.errors[-(1:burn),])+y),  
      as.numeric(p_mean)),
    # actual data and dates 
      as.numeric(full_df$cc),
      as.Date(full_df$date))
names(d2) <- c("Fitted", "Actual", "Date")
#out$pred <- p
out$MAPE_raw <- d2


#Create a Test df with the combination of the three test months
test_df <- rbind(test_1, test_2, test_3)
test <- tibble::rownames_to_column(test_df, var = "Date" )

if  ((reg == TRUE & prior == FALSE) |(reg == TRUE & prior == TRUE)){
### 95% forecast credible interval for each month's nowcasts
#First Month
p_1_pi <- cbind.data.frame(
  as.numeric(p_1$interval[1,]),
  as.numeric(p_1$interval[2,]), 
  as.Date(test$Date))
names(p_1_pi) <- c("LL", "UL", "Date")

#Second Month
p_2_pi <- cbind.data.frame(
  as.numeric(p_2$interval[1,]),
  as.numeric(p_2$interval[2,]), 
  as.Date(test$Date))
names(p_2_pi) <- c("LL", "UL", "Date")

#Third Month
p_3_pi <- cbind.data.frame(
  as.numeric(p_3$interval[1,]),
  as.numeric(p_3$interval[2,]), 
  as.Date(test$Date))
names(p_3_pi) <- c("LL", "UL", "Date")
posterior.interval <- rbind(p_1_pi, p_2_pi, p_3_pi) }
else{
  posterior.interval <-cbind.data.frame(
  as.numeric(p$interval[1,]),
  as.numeric(p$interval[2,]), 
  as.Date(test$Date))
  
  names(posterior.interval) <- c("LL", "UL", "Date")
}

### Join intervals to the forecast
d3 <- left_join(d2, posterior.interval, by="Date")
out$data_posterior <- d3

#Vertical line intercept for test period
  if(test_year < 2021){
  ### Predict
    date_intercept <- d3[34,3]
  
  }
  else if(test_year == 2021){
    date_intercept <- d3[28,3]
    
  }

#Define y axis boundaries
y_min <- min(d3$Actual, d3$Fitted, d3$LL) - 5
y_max <- max(d3$Actual, d3$Fitted, d3$UL) + 5
### Plot actual versus predicted with credible intervals for the holdout period
p <- ggplot(data=d3, aes(x=Date)) +
  geom_line(aes(y=Actual, colour = "Actual"), size=1.3) +
  geom_line(aes(y=Fitted, colour = "Fitted"), size=1.3, linetype=2) +
  scale_color_manual(values = c("#000000", custom_fill))+
  scale_x_date(date_breaks = "3 months", date_labels = "%b %Y") +
  theme_bw() + theme(legend.title = element_blank()) + ylab("") + xlab("") +
  geom_ribbon(aes(ymin=LL, ymax=UL), fill=custom_fill, alpha=0.2) +
  geom_vline(xintercept= date_intercept, linetype=3, 
                color = "black", size=0.5)+
  labs(title = title, subtitle = paste(test_year-2, test_year, sep = "-"))+
  theme(axis.text.x=element_text(angle = -90, hjust = 0), legend.position="bottom")

out$plot <- p + scale_y_continuous(limits = c(y_min, y_max))
return(out)
}
```

```{r}
### Helper function to get the positive mean of a vector
PositiveMean <- function(b) {
  b <- b[abs(b) > 0]
  if (length(b) > 0) 
    return(mean(b))
  return(0)
}
```

```{r}

param_values_bsts <- function(model, tolerance_level){
  #reference:https://multithreaded.stitchfix.com/blog/2016/04/21/forget-arima/
  ### Get the number of burn-ins to discard
  burn <- SuggestBurn(0.1, model)

  ##Look into acf function
  #Look into what other authors do 

### Get the average coefficients when variables were selected (non-zero slopes)
coeff <- data.frame(reshape2::melt(apply(model$coefficients[-(1:burn), ], 2, PositiveMean)))
coeff <- tibble::rownames_to_column(coeff, "Variable")

#Remove non-alpha numeric characters
coeff$Variable <- str_replace_all(coeff$Variable , "[^[:alnum:]]", "")

#add space between words
coeff$Variable <- gsub("([a-z])([A-Z])","\\1 \\2", coeff$Variable )

coeff <- coeff %>%
  filter(abs(value) > tolerance_level) %>%
  arrange(desc(value))


plot <- ggplot(data=coeff, aes(x=reorder(Variable, -value), y=value)) + 
  geom_bar(stat="identity", position="identity") + 
  theme(axis.text.x=element_text(angle = -90, hjust = 0)) +
  xlab("") + ylab("") + ggtitle("Average coefficients")

return(plot)
}
```

```{r}
var_inclusion_bsts <- function(model, thresh = 0.01){
  #reference:https://multithreaded.stitchfix.com/blog/2016/04/21/forget-arima/
    ### Get the number of burn-ins to discard
  burn <- SuggestBurn(0.1, model)
  ### Inclusion probabilities -- i.e., how often were the variables selected 
  inclusionprobs <- reshape2::melt(colMeans(model$coefficients[-(1:burn), ] != 0))
  inclusionprobs$Variable <- as.character(row.names(inclusionprobs))

  inclusionprobs <- inclusionprobs %>%
    filter(value > thresh) %>%
    arrange(desc(value))
plot <- ggplot(data=inclusionprobs, aes(x=Variable, y=value)) + 
  geom_bar(stat="identity", position="identity") + 
  theme(axis.text.x=element_text(angle = -90, hjust = 0)) + 
  xlab("") + ylab("") + ggtitle("Inclusion probabilities")

return(plot)
}
```

```{r}

decompose_bsts <- function(model, train_df){
  #reference:https://multithreaded.stitchfix.com/blog/2016/04/21/forget-arima/
    ### Get the number of burn-ins to discard
  burn <- SuggestBurn(0.1, model)
  train <- tibble::rownames_to_column(train_df, var="date")
### Get the components
components.withreg <- cbind.data.frame(
  colMeans(model$state.contributions[-(1:burn),"trend",]),
  colMeans(model$state.contributions[-(1:burn),"seasonal.12.1",]),
  colMeans(model$state.contributions[-(1:burn),"regression",]),
  as.Date(train$date))
names(components.withreg) <- c("Trend", "Seasonality", "Regression", "Date")
components.withreg <- melt(components.withreg, id.vars="Date")
names(components.withreg) <- c("Date", "Component", "Value")

plot <- ggplot(data=components.withreg, aes(x=Date, y=Value)) + geom_line() + 
  theme_bw() + theme(legend.title = element_blank()) + ylab("") + xlab("") + 
  facet_grid(Component ~ ., scales="free") + guides(colour=FALSE) + 
  theme(axis.text.x=element_text(angle = -90, hjust = 0))

return(plot)
}
```

```{r}
#Function to create vectors with training and test MAPE 

get_errors <- function(MAPE_df, test_year, country, reg){

  if(test_year < 2021){
  ###Get MAPE of training and test sets
    MAPE_train <- MAPE_df[1:33,] 
    MAPE_test <- MAPE_df[34:36,] 
  
  }
  else if(test_year == 2021){
    MAPE_train <- MAPE_df[1:27,] 
    MAPE_test <- MAPE_df[28:30,] 
  }

MAPE_train <- MAPE_train %>%
   summarise(MAPE_train =mean(abs(Actual-Fitted)/abs(Actual)))

MAPE_test <- MAPE_test %>%
   summarise(MAPE_test =mean(abs(Actual-Fitted)/abs(Actual)))

country_name <- c(country)

period <- c(test_year)

with_gt <- c(reg)

errors_df <- cbind(MAPE_train, MAPE_test, country_name, reg, period)

return(errors_df)

}
```


```{r}
#Function to create boxplot with errors

box_plot_errors <- function(model_w_reg, model_wo_reg, test_df){
  out <- list()
  burn_1 <- SuggestBurn(0.1, model_w_reg)
  burn_2 <- SuggestBurn(0.1, model_wo_reg)

#First get the training errors

#With regression
train_erros_reg <- c(as.numeric(-colMeans(model_w_reg$one.step.prediction.errors[-(1:burn_1),])))

#Without regression
train_erros_wo_reg <- c(as.numeric(-colMeans(model_wo_reg$one.step.prediction.errors[-(1:burn_2),])))

#Get the predictions of the test data and the errors
#With regression
p_w_reg <- predict.bsts(model_w_reg, newdata = test_df , horizon = 3, burn = burn_1, quantiles = c(0.001, .999) )


test_error_w_reg <- c(test_df$cc - p_w_reg$mean)

#Without regression
p_wo_reg <- predict.bsts(model_wo_reg, newdata = test_df , horizon = 3, burn = burn_2, quantiles = c(0.001, .999) )

test_error_wo_reg <- c(test_df$cc - p_wo_reg$mean)

#Put everything together
errors <- c(train_erros_reg, train_erros_wo_reg, test_error_w_reg, test_error_wo_reg)


my_labels <- c(rep("Training Error - GT",33), rep("Training Error - No GT", 33), rep("Test Error - GT", 3), rep("Test Error -  No GT", 3))

#Rename columns 
train <- data.frame(as.numeric(errors), as.factor(my_labels))

names(train) <- c("Errors", "Label")

out$train <- train

error_plot <- ggplot(train, aes(x=Label, y=Errors, fill=Label)) + 
    geom_boxplot(alpha=0.3) +
    theme(legend.position="none")

out$error_plot <- error_plot 

return(out)

}
```


```{r}
bsts_run_w_prior <- function(y, model_spec, seasons, iterations, train_df, initial_year, seed= 42){
   #List the variable of interest depending on the period
  #Note that the only difference is that in the 2019-2021 period, I included two COVID related variables
   if(initial_year == 2017){
    vars_cc <- c("Jobs","Investing" ,"Welfare & Unemployment", "Home & Garden", "Autos & Vehicles")
  } else{
    vars_cc <- c("Jobs","Investing" ,"Welfare & Unemployment","Public Health", "Infectious Diseases", "Home & Garden", "Autos & Vehicles")
  }
  #Get indeces of the variables of interest
  id <- which(names(train_df )%in%vars_cc) 
  
  #Create vector with 0s
  prior_spikes <- rep(0, ncol(train_df))

  #Populate indeces of interest with the prior inclusion probability
  prior_spikes <- replace(prior_spikes, id, 1)
  
  #Specify the prior
  prior <- SpikeSlabPrior(x=model.matrix(model_spec, data= train_df), 
                        y= y, 
                        #prior.information.weight = #default is 0.01,
                        prior.inclusion.probabilities = prior_spikes)
  
  ss <- AddLocalLinearTrend(list(), y)
  ss <- AddSeasonal(ss, y, nseasons = seasons)
  model <- bsts(model_spec,
               state.specification = ss,
               data = train_df,
               prior=prior, 
               niter = iterations, 
               seed = seed)
  
  return(model)
  
}
```

